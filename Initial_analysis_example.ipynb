{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Modelling Analysis of a Data Set\n",
    "Walk-through of standard analysis before modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up formatting\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "example_df = pd.read_csv('bank.csv', na_values=[np.nan])\n",
    "\n",
    "# Print high-level summary of the data frame\n",
    "print('Data Summary:')\n",
    "rows_n, columns_n = stats.df_stats(example_df)\n",
    "\n",
    "# Preview data\n",
    "print('Preview of Data:')\n",
    "print(example_df.head(3))\n",
    "print(example_df.tail(3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After reviewing data types, correct any that are wrong by putting them in a dictionary with the correct type\n",
    "dtype_dictionary = {'ID':           np.object,\n",
    "                    'Age_2':        np.int64,\n",
    "                    'Balance_2':    np.float,\n",
    "                    'Day_2':        np.int64,\n",
    "                    'Marital_2':    np.object,\n",
    "                    'Education_2':  np.object}\n",
    "\n",
    "example_df = stats.correct_dtypes(df=example_df, dtype_dictionary=dtype_dictionary)\n",
    "print('Corrected Data Types:\\n{}'.format(example_df.dtypes))\n",
    "\n",
    "# Drop features that are not meaningful for the analysis\n",
    "drop_elements = ['ID', 'Unnamed: 0']\n",
    "example_df = example_df.drop(drop_elements, axis=1)\n",
    "\n",
    "# Review target\n",
    "target = example_df['Y_2']\n",
    "print('\\nTarget Summary:')\n",
    "stats.analyse_target(target=target)\n",
    "\n",
    "# TODO: make sure target is numerical - encode\n",
    "\n",
    "# Review key stats for features\n",
    "print('\\nFeature Summary:')\n",
    "print(example_df.describe(include='all'))\n",
    "\n",
    "# Review NA values\n",
    "data_na = stats.count_na(example_df)\n",
    "print(data_na)\n",
    "\n",
    "high_na = data_na.loc[data_na['Percent'] > 0.9].index.tolist()\n",
    "print('Features with > 90% missing values to be dropped: {}'.format(len(high_na)))\n",
    "print(high_na)\n",
    "example_df = example_df.drop(high_na, axis=1)\n",
    "\n",
    "# Basic NA cleaning\n",
    "\n",
    "categorical_cols = example_df.select_dtypes(['object']).columns\n",
    "numerical_cols = example_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "example_df.fillna({x: 'unknwn' for x in categorical_cols}, inplace=True)\n",
    "example_df.fillna({x: -1 for x in numerical_cols}, inplace=True)\n",
    "\n",
    "# Group infrequent values in categorical features to 'other'\n",
    "example_df = stats.clean_cats(example_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review relationships in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numerical vs Numerical Features - Correlation\n",
    "\n",
    "high_corr_df = stats.correlated_features(df=example_df, min_corr=0.85)\n",
    "high_corr_unique_f = list(set(high_corr_df['feature 1'].unique().tolist()\n",
    "                              + high_corr_df['feature 2'].unique().tolist()))\n",
    "\n",
    "print('Number of highly correlated features: {}'.format(len(high_corr_unique_f)))\n",
    "print(high_corr_unique_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quick solution to reduce correlated features - drop the 2nd feature\n",
    "\n",
    "high_corr_f2 = high_corr_df['feature 2'].unique().tolist()\n",
    "example_df = example_df.drop(high_corr_f2, axis=1)\n",
    "\n",
    "# Plot correlations between remaining features\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "correlations = stats.correlation_plot(example_df, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remaining Numerical Features vs Categorical Target\n",
    "\n",
    "pbs_corr = stats.point_biserial_corr(df=example_df, target_col_str='Y_2')\n",
    "title = 'Numerical feature correlation with target (top 20)'\n",
    "score_label = 'correlation coefficient (r)'\n",
    "\n",
    "stats.plot_score(df=pbs_corr, score_col='corr', n=20, title=title, log_scale=False, score_label=score_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visual analysis of Top Numerical Features vs Target\n",
    "\n",
    "top_numerical_f = pbs_corr.sort_values(by='corr_abs', ascending=False)[0:20].index.tolist()\n",
    "top_numerical_f.append('Y_2')\n",
    "numerical_df_p = example_df[top_numerical_f]\n",
    "stats.plot_features(df=numerical_df_p, target_col_str='Y_2')\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical vs Categorical - chi squared test of independence\n",
    "\n",
    "print('\\nChi-squared Test for Independence:')\n",
    "chi_square_test = stats.chi_squared(example_df, target_col_str='Y_2')\n",
    "\n",
    "failed_chi = chi_square_test.loc[chi_square_test['p_value'] >= 0.05]\n",
    "failed_chi_f = failed_chi.index.tolist()\n",
    "print('Accept null hypothesis - no apparent association with target:')\n",
    "print(failed_chi_f)\n",
    "\n",
    "passed_chi = chi_square_test.loc[chi_square_test['p_value'] < 0.05]\n",
    "passed_chi_f = passed_chi.index.tolist()\n",
    "print('Reject null hypothesis - apparent association with target:')\n",
    "print(passed_chi_f)\n",
    "\n",
    "invalid_chi = chi_square_test.loc[chi_square_test['p_value'].isnull()]\n",
    "invalid_chi_f = invalid_chi.index.tolist()\n",
    "print('Did not meet assumptions for test (>20% of expected counts <5):')\n",
    "print(invalid_chi_f)\n",
    "# need to divert these to another test (e.g. Fishers Exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visual analysis of Categorical Features\n",
    "\n",
    "top_categorical_f = passed_chi_f + invalid_chi_f + 'Y_2'\n",
    "\n",
    "categorical_df_p = example_df[top_categorical_f]\n",
    "stats.plot_features(df=categorical_df_p, target_col_str='Y_2')\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
